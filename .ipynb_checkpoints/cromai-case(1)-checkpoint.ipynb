{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os # manipulação de diretório\nimport pandas as pd\nimport shutil # manipulação de diretório\nimport matplotlib.pyplot as plt # plots\nimport cv2 # OpenCV ou cv2 para tratamento de imagens;\nimport numpy as np # Numpy para trabalharmos com matrizes n-dimensionais\nfrom keras.models import Sequential # Importando modelo \nfrom keras.applications import ResNet101, Xception # Modelo ResNet pré treinado\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D # Camada de convolução e max pooling\nfrom keras.layers.core import Activation, Flatten, Dense, Dropout # Camada da função de ativação, flatten, entre outros\nfrom keras import backend as K # backend do keras\nfrom keras.optimizers import Adam, SGD # optimizador Adam\nfrom keras.preprocessing.image import img_to_array # Função de conversão da imagem para um vetor\nfrom keras.utils import to_categorical # Função utilizada para categorizar listas de treino e teste\nfrom keras.preprocessing.image import ImageDataGenerator # Classe para ajudar na variação de amostras de treinamento\nfrom keras.callbacks import ModelCheckpoint # Classe utilizada para acompanhamento durante o treinamento onde definimos os atributos que serão considerados para avaliação\n#Kaggle notebook input directory\ninput_path = '/kaggle/input/dataset-cats-and-dogs/cats_and_dogs/'\ndst_path = '../working/'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def move_folder(input_folder, group_data, dst_path):\n    # Função criada para trabalhar no diretório do notebook Kaggle para usufruir de sua GPU\n    # Muda o dataset de diretório\n    counter=0\n    final_dst=os.path.join(dst_path, group_data)\n    if not os.path.exists(final_dst):\n        os.makedirs(final_dst)\n    for group in os.listdir(input_folder):\n        if os.path.isdir(os.path.join(input_folder, group)):\n            group_path = os.path.join(input_folder, group)\n            for img in os.listdir(group_path):\n                counter+=1\n                shutil.copy2(group_path+'/'+img, final_dst+'/'+img)\n    print(str(counter) + \"files were replaced\")","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def get_data_x_and_y(data_path, width, height, depth, classes):\n    \"\"\"]\n    Essa função itera pelo data_path para separar dados como rotulos e\n        os dados que serão utilizados para o treinamento e teste\n\n    Args:\n        data_path: O diretório com os dados\n        width: Largura das matriz esperada pelo modelo\n        height: Altura das matriz esperada pelo modelo\n        classes: Numero de classes que o modelo utilizará\n\n    Returns:\n        Uma tupla onde na primeira posição você tem o eixo X e na segunda posição o eixo Y\n    \"\"\"\n    labels = []\n    data = []\n    # itera pelo diretório\n    for filename in os.listdir(data_path):\n        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n            # faz a leitura de cada imagem\n            image = cv2.imread(os.path.join(data_path, filename))\n            if depth == 1:\n                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n            # redimensiona a imagem\n            image = cv2.resize(image, (width, height))\n            # converte a imagem para um vetor\n            image = img_to_array(image)\n            # concatena a imagem a lista de dados que serão utilizados pelo treinamento\n            data.append(image)\n            # concatena a lista de rotulos a classe da imagem\n            labels.append(int(filename[5])-1)\n    # Normaliza os dados de treinamento\n    X = np.array(data, dtype=\"float32\") / 255.0\n    # Categoriza os rotulos\n    Y = to_categorical(labels, num_classes=classes)\n    return (X, Y)","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def create_lenet(input_shape):\n    \"\"\"\n    Cria uma mini arquitetura lenet\n\n    Args:\n        input_shape: Uma lista de três valores inteiros que definem a forma de\\\n                entrada da rede. Exemplo: [100, 100, 3]\n\n    Returns:\n        Um modelo sequencial, seguindo a arquitetura lenet\n    \"\"\"\n    # Definimos que estamos criando um modelo sequencial\n    model = Sequential()\n\n    # Primeira camada do modelo:\n    model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=input_shape))\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n    # Segunda camada do modelo:\n    model.add(Conv2D(50, (5, 5), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n    # Primeira camada fully connected\n    model.add(Flatten())\n    model.add(Dense(500))\n    model.add(Activation(\"relu\"))\n\n    # Classificador softmax\n    model.add(Dense(classes))\n    model.add(Activation(\"softmax\"))\n    return model","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def create_model_2(input_shape):\n    \"\"\"\n    Modelo baseado na LeNet\n    Acréscimo de um layer convolucional 3x3 na segunda camada da rede.\n    \"\"\"\n    # Definimos que estamos criando um modelo sequencial\n    model = Sequential()\n\n    # Primeira camada do modelo:\n    model.add(Conv2D(20, (5, 5), padding=\"same\", input_shape=input_shape))\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\n    # Segunda camada do modelo:\n    model.add(Conv2D(50, (3, 3), padding=\"same\")) # Layer adicionado\n    model.add(Conv2D(50, (5, 5), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n    \n    # Primeira camada fully connected\n    model.add(Flatten())\n    model.add(Dense(500))\n    model.add(Activation(\"relu\"))\n\n    # Classificador softmax\n    model.add(Dense(2))\n    model.add(Activation(\"softmax\"))\n    return model","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def create_model_3(input_shape):\n    \"\"\"\n    Cria um modelo com a arquitetura Xception do projeto Image Net, já pré treinada\n    Técnica conhecida como Transfer Learning\n    \"\"\"\n    \n    # Definimos que estamos criando um modelo sequencial\n    model = Sequential()\n\n    base = Xception(weights=\"imagenet\", include_top=False) ## Modelo base\n    model.add(base)\n    model.add(GlobalAveragePooling2D())\n    model.add(Flatten())\n    model.add(Dropout(0.25))\n    model.add(Dense(250, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(2, activation=\"softmax\"))\n\n    return model","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def plot_accs(result, epochs):\n    # Plota válores da acurácia de treino/validação\n    # plota valores do loss para treino/validação\n    acc = result.history['accuracy']\n    loss = result.history['loss']\n    val_acc = result.history['val_accuracy']\n    val_loss = result.history['val_loss']\n    plt.figure(figsize=(15, 5))\n    plt.subplot(121)\n    plt.plot(range(1,epochs), acc[1:], label='Train_acc')\n    plt.plot(range(1,epochs), val_acc[1:], label='Test_acc')\n    plt.title('Accuracy over ' + str(epochs) + ' Epochs', size=15)\n    plt.legend()\n    plt.grid(True)\n    plt.subplot(122)\n    plt.plot(range(1,epochs), loss[1:], label='Train_loss')\n    plt.plot(range(1,epochs), val_loss[1:], label='Test_loss')\n    plt.title('Loss over ' + str(epochs) + ' Epochs', size=15)\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    train_path = os.path.join(input_path, 'train/') # Adicione aqui o caminho para chegar no diretório que contém as imagens de treino na sua maquina\n    test_path = os.path.join(input_path, 'test/') # Adicione aqui o caminho para chegar no diretório que contém as imagens de teste na sua maquina\n    models_path = os.path.join(dst_path, 'model/') # Defina aqui onde serão salvos os modelos na sua maquina\n    width = 100 # Tamanho da largura da janela que será utilizada pelo modelo\n    height = 100 # Tamanho da altura da janela que será utilizada pelo modelo\n    depth = 1 # Profundidade das janelas utilizadas pelo modelo, caso seja RGB use 3, caso escala de cinza 1\n    classes = 2 # Quantidade de classes que o modelo utilizará\n    epochs = 10 # Quantidade de épocas (a quantidade de iterações que o modelo realizará durante o treinamento)\n    init_lr = 1e-3 # Taxa de aprendizado a ser utilizado pelo optimizador\n    batch_size = 32 # Tamanho dos lotes utilizados por cada epoca\n    input_shape = (height, width, depth) # entrada do modelo\n    save_model = os.path.join(models_path, \"lenet-{epoch:02d}-{accuracy:.3f}-{val_accuracy:.3f}.model\")\n    os.makedirs(models_path, exist_ok=True)\n\n    # Treinando rede LeNet dada\n    (trainX, trainY) = get_data_x_and_y(train_path, width, height, depth, classes)\n    (testX, testY) = get_data_x_and_y(test_path, width, height, depth, classes)\n\n    aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n                height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n                fill_mode=\"nearest\")\n\n    model = create_lenet(input_shape)\n\n    opt = Adam(lr=init_lr, decay=init_lr / epochs)\n\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n    model.summary()\n\n    print(\"\\n training network 1\")\n\n    checkpoint1 = ModelCheckpoint(save_model, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n    checkpoint2 = ModelCheckpoint(save_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n    callbacks_list = [checkpoint1,checkpoint2]\n\n    H = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n            validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n            epochs=epochs, verbose=1,callbacks=callbacks_list)\n    \n    df = pd.DataFrame.from_dict(H.history)\n    df.to_csv(dst_path + \"lenet.csv\", index=False)    \n        \n    ## Treinando segunda arquitetura\n     # - Mudança: Width, heigth, depth e epochs\n        # Mudança: Acréscimo de um layer Convolucional 3x3 na seguda camada\n    \n    width = 128 # Tamanho da largura da janela que será utilizada pelo modelo\n    height = 128 # Tamanho da altura da janela que será utilizada pelo modelo\n    depth = 1 # Tamanho da largura da janela que será utilizada pelo modelo\n    epochs = 15 # Quantidade de épocas\n\n    save_model = os.path.join(models_path, \"model2-{epoch:02d}-{accuracy:.3f}-{val_accuracy:.3f}.model\")\n    (trainX, trainY) = get_data_x_and_y(train_path, width, height, depth, classes)\n    (testX, testY) = get_data_x_and_y(test_path, width, height, depth, classes)\n\n    aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n                height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n                fill_mode=\"nearest\")\n\n    model = create_model_2(input_shape)\n\n    opt = Adam(lr=init_lr, decay=init_lr / epochs)\n    \n    print(\"\\n training network 2\")\n\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n    model.summary()\n    checkpoint1 = ModelCheckpoint(save_model, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n    checkpoint2 = ModelCheckpoint(save_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n    callbacks_list = [checkpoint1,checkpoint2]\n\n    H = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n            validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n            epochs=epochs, verbose=1,callbacks=callbacks_list)\n    \n    df = pd.DataFrame.from_dict(H.history)\n    df.to_csv(dst_path + \"model2.csv\", index=False)    \n    \n    ## Treinando terceira arquitetura\n    # Mudança - Modelo Xception\n    depth = 3 # Profundidade mudada - escala RGB\n    save_model = os.path.join(models_path, \"model3-{epoch:02d}-{accuracy:.3f}-{val_accuracy:.3f}.model\")\n    os.makedirs(models_path, exist_ok=True)\n\n    (trainX, trainY) = get_data_x_and_y(train_path, width, height, depth, classes)\n    (testX, testY) = get_data_x_and_y(test_path, width, height, depth, classes)\n\n    aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n                height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n                fill_mode=\"nearest\")\n    opt = Adam(lr=init_lr, decay=init_lr / epochs)\n\n    model = create_model_3(input_shape)\n    \n    print(\"\\n training network 3\")\n\n    model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n    model.summary()\n\n    checkpoint1 = ModelCheckpoint(save_model, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n    checkpoint2 = ModelCheckpoint(save_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n    callbacks_list = [checkpoint1,checkpoint2]\n\n    H = model.fit_generator(aug.flow(trainX, trainY, batch_size=batch_size),\n            validation_data=(testX, testY), steps_per_epoch=len(trainX) // batch_size,\n            epochs=epochs, verbose=1, callbacks=callbacks_list)\n    \n    plot_accs(H, epochs)\n    \n    df = pd.DataFrame.from_dict(H.history)\n    df.to_csv(dst_path + \"model3.csv\", index=False)","metadata":{"trusted":true},"execution_count":13,"outputs":[]}]}